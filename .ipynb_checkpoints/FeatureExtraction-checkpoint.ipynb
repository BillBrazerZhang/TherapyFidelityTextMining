{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import urllib.request\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "class KeywordCount:\n",
    "    def __init__(self, fname):\n",
    "        self.name = fname  #file name of input transcript\n",
    "        #init for updateWordCount()\n",
    "        self.words = []  #sequenced word list\n",
    "        self.wordCount = defaultdict(int)  #dictionary of words and their count\n",
    "        self.wordCountSort = defaultdict(int)  #sorted dictionary\n",
    "        self.transSize = 0  #words the transcript have\n",
    "        self.transSizeNS = 0  #meaningful words the transcript have\n",
    "        self.wordsetSize = 0  #all different words\n",
    "        #init for updateKeywordStatistics()\n",
    "        self.keywordStat = defaultdict(dict)  #num(int) certain keyword appears in the transcript\n",
    "        self.keywordLoc = defaultdict(dict)  #locations(list) certain keyword appears in the transcript\n",
    "        self.keywordPart = defaultdict(dict)  #percentage per keyword from all keywords\n",
    "        self.keywordPer = float(0)  #percentage all keywords from all words\n",
    "        #init for questionMark()\n",
    "        self.questionStat = 0\n",
    "        self.questionLoc = []\n",
    "        self.questionPer = float(0)\n",
    "\n",
    "        print(\"Reading data...\")\n",
    "        print(\"Parsing by words...\")\n",
    "        with open(fname, encoding='utf-8', errors='ignore') as f:\n",
    "            data = f.read()\n",
    "        tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "        self.data = tokenizer.tokenize(data)\n",
    "        print(\"Parsing by sentences...\")\n",
    "        from nltk.tokenize import sent_tokenize\n",
    "        self.sentNum = 0 \n",
    "        self.sents = []\n",
    "        with open(fname, encoding='utf-8', errors='ignore') as f:\n",
    "            for line in f:\n",
    "                line = line.lower()\n",
    "                self.sentNum += len(sent_tokenize(line))\n",
    "                for sent in sent_tokenize(line):\n",
    "                    self.sents.append(sent)\n",
    "\n",
    "        print(\"done\")\n",
    "\n",
    "        print(\"Initializing keword dictionary...\")\n",
    "        # Dictionary of key-terms for CTS fidelity\n",
    "        self.keywordCTS = defaultdict(set)\n",
    "\n",
    "        self.keywordCTS['Agenda'] = {'agenda','priorities','most important','focus on first','talk about today','work on today','focus on during the session','work on' \\\n",
    "                                ,'you like to add to the agenda','you like to add anything to the agenda','you want to add to the agenda' \\\n",
    "                                ,'you want to add anything to the agenda','last week'}\n",
    "\n",
    "        self.keywordCTS['Feedback'] = {'feedback','previous','last time','last week','last session','past session' \\\n",
    "                                  ,'think about today','things go today','think about today\\'s session','concern','unhelpful','helpful' \\\n",
    "                                  ,'anything i can do better','anything we can do better','concerns about today\\'s session','helpful about the session' \\\n",
    "                                  ,'learn','skills','achieve','goals','if i understand you correctly', 'are you saying', 'do i have it right'}\n",
    "\n",
    "        self.keywordCTS['Understanding'] = {'understand','understanding','sounds like','you are saying','you are feeling','you were feeling','you felt' \\\n",
    "                                       ,'see','makes sense','i see','feel that way','feel this way'}\n",
    "\n",
    "        self.keywordCTS['Interpersonal Effectiveness'] = {'sorry','hard','difficult','tough' \\\n",
    "                                                     ,'dissappointing','stressful','stressed' \\\n",
    "                                                     ,'scary','frightening','upset','upsetting'\\\n",
    "                                                     ,'unfortunate'}\n",
    "\n",
    "        self.keywordCTS['Collaboration'] = {'choice', 'you want to do','good idea','because','will','help you get your goal'}\n",
    "\n",
    "        self.keywordCTS['Guided Discovery'] = {'meaning','mean','self','how','why','evidence' \\\n",
    "                                          ,'conclusion','conclude','decide','decision','decided' \\\n",
    "                                          ,'know','proof','tell me more','assume','assumption' \\\n",
    "                                          ,'hypothesis','disprove','facts','fact','solutions' \\\n",
    "                                          ,'brainstorm','solve','alternative','other explanations' \\\n",
    "                                          ,'another way','other way','to think about','to explain','reason'} \n",
    "\n",
    "        self.keywordCTS['Focus on Key Cognitions'] = {'thinking','tell yourself','through your mind' \\\n",
    "                                                 ,'thought','think','connection','lead to','connected' \\\n",
    "                                                 ,'connect','link','linked','make you','you do'}\n",
    "\n",
    "        self.keywordCTS['Choices of Intervention'] = {}\n",
    "\n",
    "        self.keywordCTS['Homework'] = {'homework','review','at home','practice','assignment','assign' \\\n",
    "                                  ,'assigned','progress','learned','improve','learn','skills' \\\n",
    "                                  ,'goal','better','barrier','in the way','expect','problems','succeed','success'}\n",
    "\n",
    "        self.keywordCTS['Social Skills Training'] = {'rational','help you learn this skill','help you with your goal' \\\n",
    "                                                ,'demonstrate','to make your next role','play better','play even better','try to focus on'}\n",
    "                                                           \n",
    "\n",
    "    def updateWordCount(self):\n",
    "        print('Starting counting words...')\n",
    "        stopWords = set(stopwords.words(\"english\"))\n",
    "        # Ignore capitalization and remove punctuation\n",
    "        punctuation = set(string.punctuation)\n",
    "        stemmer = PorterStemmer()\n",
    "        for d in self.data:\n",
    "            r = ''.join([c for c in d if not c in punctuation])\n",
    "            if r != '':\n",
    "                w = stemmer.stem(r.lower())\n",
    "                self.words.append(w)\n",
    "                self.transSize += 1\n",
    "                if not w in stopWords:\n",
    "                    self.wordCount[w] += 1\n",
    "                    self.transSizeNS += 1\n",
    "        self.wordsetSize = len(self.wordCount)\n",
    "        self.wordCountSort = sorted(self.wordCount.items(), key = lambda kv: kv[1])\n",
    "        print('Word counting done.')\n",
    "\n",
    "    def updateKeywordStatistics(self):\n",
    "        print('Starting keyword statisics...')\n",
    "        s = 0\n",
    "        for k1 in self.keywordCTS.keys():\n",
    "            for k2 in self.keywordCTS[k1]:\n",
    "                self.keywordStat[k1][k2] = 0\n",
    "                if len(k2.split()) == 1:\n",
    "                    if k2 in self.wordCount.keys():\n",
    "                        self.keywordStat[k1][k2] = self.wordCount[k2]\n",
    "                        s += self.wordCount[k2]\n",
    "                        loc = []\n",
    "                        cap = len(self.words)\n",
    "                        for i in range(cap):\n",
    "                            if self.words[i] == k2:\n",
    "                                loc.append(float(i)/float(cap))\n",
    "                        self.keywordLoc[k1][k2] = loc\n",
    "                else: \n",
    "                    loc = []\n",
    "                    for i in range(self.sentNum):\n",
    "                        if k2 in self.sents[i]:\n",
    "                            self.keywordStat[k1][k2] += self.sents[i].count(k2)\n",
    "                            s += self.sents[i].count(k2)\n",
    "                            for j in range(self.sents[i].count(k2)):\n",
    "                                loc.append(float(i)/float(self.sentNum))\n",
    "                    if self.keywordStat[k1][k2] > 0:\n",
    "                        self.keywordLoc[k1][k2] = loc\n",
    "        for k1 in self.keywordStat.keys():\n",
    "            for k2 in self.keywordStat[k1].keys():\n",
    "                self.keywordPart[k1][k2] = self.keywordStat[k1][k2]/float(s)\n",
    "        self.keywordPer = s/float(self.transSize)\n",
    "        print('Keyword statistics done.')\n",
    "\n",
    "    def questionMark(self):\n",
    "        print('Starting questionmark statistics...')\n",
    "        l = len(self.data)\n",
    "        for i in range(l):\n",
    "            if self.data[i] == '?':\n",
    "                self.questionStat += 1\n",
    "                self.questionLoc.append(float(i)/float(l))\n",
    "        self.questionPer = float(self.questionStat)/float(self.sentNum)\n",
    "        print('Questionmark statistics done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Parsing by words...\n",
      "Parsing by sentences...\n",
      "done\n",
      "Initializing keword dictionary...\n",
      "Starting counting words...\n",
      "Word counting done.\n",
      "Starting keyword statisics...\n",
      "Keyword statistics done.\n",
      "Starting questionmark statistics...\n",
      "Questionmark statistics done.\n"
     ]
    }
   ],
   "source": [
    "t1 = KeywordCount('Transcript1.txt')\n",
    "t1.updateWordCount()\n",
    "t1.updateKeywordStatistics()\n",
    "t1.questionMark()\n",
    "f = open('Feature'+t1.name,'w')\n",
    "f.write('File name: ' + t1.name + '\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Object: ' + 'Overall' + '\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Keyword Dictionary:' + '\\n')\n",
    "f.write(str(t1.keywordCTS))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Feature 1: times(int) certain keyword appears in the transcript ' + '\\n')\n",
    "f.write(str(t1.keywordStat))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Feature 2: locations(list of floats) certain keyword appears in the transcrip' + '\\n')\n",
    "f.write(str(t1.keywordLoc))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Feature 3: percentage per keyword from all keywords' + '\\n')\n",
    "f.write(str(t1.keywordPart))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Feature 4: percentage of all keywords from all words' + '\\n')\n",
    "f.write(str(t1.keywordPer))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Feature 5: questionmarks count' + '\\n')\n",
    "f.write(str(t1.questionStat))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Feature 6: questionmarks location' + '\\n')\n",
    "f.write(str(t1.questionLoc))\n",
    "f.write('\\n')\n",
    "f.write('========================================================================================' + '\\n')\n",
    "f.write('Feature 7: percentage of sentences ending with questionmark from all sentences' + '\\n')\n",
    "f.write(str(t1.questionPer))\n",
    "f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
